{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset/processed_data/final_dataset.csv')\n",
    "\n",
    "descriptions = df['description']  \n",
    "domains = df['domain'] \n",
    "sub_domains = df['sub_domain']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize descriptions\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(descriptions)\n",
    "X = tokenizer.texts_to_sequences(descriptions)\n",
    "X = pad_sequences(X, padding='post', maxlen=100)  # Adjust maxlen as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode labels (domain and sub_domain)\n",
    "domain_encoder = joblib.load(\"../models/domain_label_encoder.pkl\")\n",
    "sub_domain_encoder = joblib.load(\"../models/sub_domain_label_encoder.pkl\")\n",
    "y_domain = domain_encoder.transform(domains)\n",
    "y_sub_domain = sub_domain_encoder.transform(sub_domains)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_domain = tf.keras.utils.to_categorical(y_domain, num_classes=len(domain_encoder.classes_))\n",
    "y_sub_domain = tf.keras.utils.to_categorical(y_sub_domain, num_classes=len(sub_domain_encoder.classes_))\n",
    "\n",
    "\n",
    "# Split data into train (80%) and validation (20%)\n",
    "X_train, X_val, y_domain_train, y_domain_val, y_sub_train, y_sub_val = train_test_split(\n",
    "    X, y_domain, y_sub_domain, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build Neural Network Model\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "embedding_layer = Embedding(input_dim=10000, output_dim=128, input_length=X.shape[1])(input_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(embedding_layer)\n",
    "dropout_layer = Dropout(0.5)(lstm_layer)\n",
    "dense_layer = Dense(64, activation='relu')(dropout_layer)\n",
    "\n",
    "# Domain Output Layer\n",
    "domain_output = Dense(len(domain_encoder.classes_), activation='softmax', name='domain')(dense_layer)\n",
    "\n",
    "# Sub-Domain Output Layer\n",
    "sub_domain_output = Dense(len(sub_domain_encoder.classes_), activation='softmax', name='sub_domain')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[domain_output, sub_domain_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ domain (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sub_domain (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,990</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ domain (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m260\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sub_domain (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │      \u001b[38;5;34m2,990\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,818</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,336,818\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,818</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,336,818\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with separate metrics for each output\n",
    "model.compile(optimizer='adam',\n",
    "              loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "              metrics=[['accuracy'], ['accuracy']])  \n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 95ms/step - domain_accuracy: 0.7873 - domain_loss: 0.5174 - loss: 3.1405 - sub_domain_accuracy: 0.1764 - sub_domain_loss: 2.6231 - val_domain_accuracy: 0.9871 - val_domain_loss: 0.0457 - val_loss: 1.5264 - val_sub_domain_accuracy: 0.3817 - val_sub_domain_loss: 1.4803\n",
      "Epoch 2/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 106ms/step - domain_accuracy: 0.9885 - domain_loss: 0.0434 - loss: 1.3923 - sub_domain_accuracy: 0.4737 - sub_domain_loss: 1.3489 - val_domain_accuracy: 0.9925 - val_domain_loss: 0.0265 - val_loss: 0.7530 - val_sub_domain_accuracy: 0.7406 - val_sub_domain_loss: 0.7262\n",
      "Epoch 3/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 93ms/step - domain_accuracy: 0.9923 - domain_loss: 0.0286 - loss: 0.7446 - sub_domain_accuracy: 0.7443 - sub_domain_loss: 0.7160 - val_domain_accuracy: 0.9903 - val_domain_loss: 0.0394 - val_loss: 0.6259 - val_sub_domain_accuracy: 0.8087 - val_sub_domain_loss: 0.5863\n",
      "Epoch 4/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 78ms/step - domain_accuracy: 0.9932 - domain_loss: 0.0274 - loss: 0.5592 - sub_domain_accuracy: 0.8242 - sub_domain_loss: 0.5319 - val_domain_accuracy: 0.9932 - val_domain_loss: 0.0275 - val_loss: 0.5207 - val_sub_domain_accuracy: 0.8477 - val_sub_domain_loss: 0.4930\n",
      "Epoch 5/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 68ms/step - domain_accuracy: 0.9950 - domain_loss: 0.0184 - loss: 0.4356 - sub_domain_accuracy: 0.8698 - sub_domain_loss: 0.4172 - val_domain_accuracy: 0.9929 - val_domain_loss: 0.0314 - val_loss: 0.5087 - val_sub_domain_accuracy: 0.8598 - val_sub_domain_loss: 0.4771\n",
      "Epoch 6/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 81ms/step - domain_accuracy: 0.9960 - domain_loss: 0.0151 - loss: 0.3750 - sub_domain_accuracy: 0.8908 - sub_domain_loss: 0.3599 - val_domain_accuracy: 0.9933 - val_domain_loss: 0.0286 - val_loss: 0.5050 - val_sub_domain_accuracy: 0.8618 - val_sub_domain_loss: 0.4762\n",
      "Epoch 7/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 78ms/step - domain_accuracy: 0.9966 - domain_loss: 0.0128 - loss: 0.3192 - sub_domain_accuracy: 0.9077 - sub_domain_loss: 0.3064 - val_domain_accuracy: 0.9927 - val_domain_loss: 0.0349 - val_loss: 0.5181 - val_sub_domain_accuracy: 0.8632 - val_sub_domain_loss: 0.4829\n",
      "Epoch 8/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m713s\u001b[0m 86ms/step - domain_accuracy: 0.9967 - domain_loss: 0.0127 - loss: 0.2801 - sub_domain_accuracy: 0.9222 - sub_domain_loss: 0.2673 - val_domain_accuracy: 0.9931 - val_domain_loss: 0.0348 - val_loss: 0.5472 - val_sub_domain_accuracy: 0.8643 - val_sub_domain_loss: 0.5121\n",
      "Epoch 9/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 76ms/step - domain_accuracy: 0.9971 - domain_loss: 0.0103 - loss: 0.2361 - sub_domain_accuracy: 0.9338 - sub_domain_loss: 0.2258 - val_domain_accuracy: 0.9931 - val_domain_loss: 0.0351 - val_loss: 0.5754 - val_sub_domain_accuracy: 0.8635 - val_sub_domain_loss: 0.5400\n",
      "Epoch 10/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 72ms/step - domain_accuracy: 0.9953 - domain_loss: 0.0165 - loss: 0.2383 - sub_domain_accuracy: 0.9369 - sub_domain_loss: 0.2217 - val_domain_accuracy: 0.9926 - val_domain_loss: 0.0383 - val_loss: 0.6001 - val_sub_domain_accuracy: 0.8648 - val_sub_domain_loss: 0.5615\n",
      "Epoch 11/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 72ms/step - domain_accuracy: 0.9974 - domain_loss: 0.0083 - loss: 0.1841 - sub_domain_accuracy: 0.9490 - sub_domain_loss: 0.1758 - val_domain_accuracy: 0.9931 - val_domain_loss: 0.0373 - val_loss: 0.6100 - val_sub_domain_accuracy: 0.8640 - val_sub_domain_loss: 0.5724\n",
      "Epoch 12/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 79ms/step - domain_accuracy: 0.9976 - domain_loss: 0.0080 - loss: 0.1715 - sub_domain_accuracy: 0.9529 - sub_domain_loss: 0.1635 - val_domain_accuracy: 0.9925 - val_domain_loss: 0.0454 - val_loss: 0.6532 - val_sub_domain_accuracy: 0.8642 - val_sub_domain_loss: 0.6075\n",
      "Epoch 13/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 74ms/step - domain_accuracy: 0.9975 - domain_loss: 0.0105 - loss: 0.1569 - sub_domain_accuracy: 0.9588 - sub_domain_loss: 0.1464 - val_domain_accuracy: 0.9929 - val_domain_loss: 0.0420 - val_loss: 0.6906 - val_sub_domain_accuracy: 0.8620 - val_sub_domain_loss: 0.6483\n",
      "Epoch 14/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 79ms/step - domain_accuracy: 0.9978 - domain_loss: 0.0078 - loss: 0.1393 - sub_domain_accuracy: 0.9624 - sub_domain_loss: 0.1315 - val_domain_accuracy: 0.9930 - val_domain_loss: 0.0390 - val_loss: 0.6921 - val_sub_domain_accuracy: 0.8631 - val_sub_domain_loss: 0.6528\n",
      "Epoch 15/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m849s\u001b[0m 103ms/step - domain_accuracy: 0.9979 - domain_loss: 0.0069 - loss: 0.1278 - sub_domain_accuracy: 0.9658 - sub_domain_loss: 0.1209 - val_domain_accuracy: 0.9932 - val_domain_loss: 0.0408 - val_loss: 0.7078 - val_sub_domain_accuracy: 0.8631 - val_sub_domain_loss: 0.6667\n",
      "Epoch 16/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 105ms/step - domain_accuracy: 0.9980 - domain_loss: 0.0065 - loss: 0.1172 - sub_domain_accuracy: 0.9691 - sub_domain_loss: 0.1107 - val_domain_accuracy: 0.9931 - val_domain_loss: 0.0464 - val_loss: 0.7440 - val_sub_domain_accuracy: 0.8642 - val_sub_domain_loss: 0.6972\n",
      "Epoch 17/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 105ms/step - domain_accuracy: 0.9976 - domain_loss: 0.0093 - loss: 0.1208 - sub_domain_accuracy: 0.9686 - sub_domain_loss: 0.1114 - val_domain_accuracy: 0.9925 - val_domain_loss: 0.0456 - val_loss: 0.7873 - val_sub_domain_accuracy: 0.8615 - val_sub_domain_loss: 0.7413\n",
      "Epoch 18/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m877s\u001b[0m 106ms/step - domain_accuracy: 0.9984 - domain_loss: 0.0056 - loss: 0.1009 - sub_domain_accuracy: 0.9735 - sub_domain_loss: 0.0953 - val_domain_accuracy: 0.9930 - val_domain_loss: 0.0513 - val_loss: 0.8417 - val_sub_domain_accuracy: 0.8629 - val_sub_domain_loss: 0.7899\n",
      "Epoch 19/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m897s\u001b[0m 109ms/step - domain_accuracy: 0.9977 - domain_loss: 0.0091 - loss: 0.1048 - sub_domain_accuracy: 0.9739 - sub_domain_loss: 0.0957 - val_domain_accuracy: 0.9930 - val_domain_loss: 0.0489 - val_loss: 0.8203 - val_sub_domain_accuracy: 0.8629 - val_sub_domain_loss: 0.7711\n",
      "Epoch 20/20\n",
      "\u001b[1m8249/8249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m900s\u001b[0m 109ms/step - domain_accuracy: 0.9980 - domain_loss: 0.0071 - loss: 0.0943 - sub_domain_accuracy: 0.9753 - sub_domain_loss: 0.0872 - val_domain_accuracy: 0.9927 - val_domain_loss: 0.0481 - val_loss: 0.8578 - val_sub_domain_accuracy: 0.8641 - val_sub_domain_loss: 0.8093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, [y_domain_train, y_sub_train],\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, [y_domain_val, y_sub_val]),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1032/1032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 30ms/step - domain_accuracy: 0.9926 - domain_loss: 0.0487 - loss: 0.8517 - sub_domain_accuracy: 0.8661 - sub_domain_loss: 0.8030\n",
      "Validation Accuracy - Domain: 0.9927, Sub-Domain: 0.8641\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation set\n",
    "val_loss, val_domain_loss, val_sub_loss, val_domain_acc, val_sub_acc = model.evaluate(\n",
    "    X_val, [y_domain_val, y_sub_val])\n",
    "print(\n",
    "    f\"Validation Accuracy - Domain: {val_domain_acc:.4f}, Sub-Domain: {val_sub_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted Domain: ['Ecommerce']\n",
      "Predicted Sub-Domain: ['Household']\n"
     ]
    }
   ],
   "source": [
    "description_input = [\"\"\"Battery Details- Type: Tall tubular batteryCapacity : 200Ah/12V: Construction: rugged construction\n",
    "Warranty -66 months ( 48 FOC+18Pro Rata)\n",
    "Dimension (in cm) - 512x192x466\n",
    "Weight- 64.8K.G\"\"\"]\n",
    "description_seq = tokenizer.texts_to_sequences(description_input)\n",
    "description_padded = pad_sequences(description_seq, padding='post', maxlen=100)\n",
    "\n",
    "domain_pred, sub_domain_pred = model.predict(description_padded)\n",
    "domain_pred_label = domain_encoder.inverse_transform(\n",
    "    domain_pred.argmax(axis=1))\n",
    "sub_domain_pred_label = sub_domain_encoder.inverse_transform(\n",
    "    sub_domain_pred.argmax(axis=1))\n",
    "\n",
    "print(f\"Predicted Domain: {domain_pred_label}\")\n",
    "print(f\"Predicted Sub-Domain: {sub_domain_pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and necessary objects saved successfully! 🎯\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model.save(\"../models/LSTM/multi_label_model.keras\")\n",
    "\n",
    "# Save the tokenizer\n",
    "joblib.dump(tokenizer, \"../models/LSTM/tokenizer.pkl\")\n",
    "\n",
    "print(\"Model and necessary objects saved successfully! 🎯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = load_model(\"../models/LSTM/multi_label_model.h5\")\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = joblib.load(\"../models/LSTM/tokenizer.pkl\")\n",
    "\n",
    "# Load Label Encoders\n",
    "domain_encoder = joblib.load(\"../models/domain_label_encoder.pkl\")\n",
    "\n",
    "\n",
    "sub_domain_encoder = joblib.load(\"../models/sub_domain_label_encoder.pkl\")\n",
    "\n",
    "print(\"Model and necessary objects loaded successfully! 🚀\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
