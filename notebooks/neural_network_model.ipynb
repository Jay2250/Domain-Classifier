{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset/processed_data/final_dataset.csv')\n",
    "\n",
    "descriptions = df['description']  \n",
    "domains = df['domain'] \n",
    "sub_domains = df['sub_domain']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize descriptions\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(descriptions)\n",
    "X = tokenizer.texts_to_sequences(descriptions)\n",
    "X = pad_sequences(X, padding='post', maxlen=100)  # Adjust maxlen as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode labels (domain and sub_domain)\n",
    "domain_encoder = LabelEncoder()\n",
    "sub_domain_encoder = LabelEncoder()\n",
    "y_domain = domain_encoder.fit_transform(domains)\n",
    "y_sub_domain = sub_domain_encoder.fit_transform(sub_domains)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_domain = tf.keras.utils.to_categorical(y_domain, num_classes=len(domain_encoder.classes_))\n",
    "y_sub_domain = tf.keras.utils.to_categorical(y_sub_domain, num_classes=len(sub_domain_encoder.classes_))\n",
    "\n",
    "\n",
    "# Split data into train (80%) and validation (20%)\n",
    "X_train, X_val, y_domain_train, y_domain_val, y_sub_train, y_sub_val = train_test_split(\n",
    "    X, y_domain, y_sub_domain, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build Neural Network Model\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "embedding_layer = Embedding(input_dim=10000, output_dim=128, input_length=X.shape[1])(input_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(embedding_layer)\n",
    "dropout_layer = Dropout(0.5)(lstm_layer)\n",
    "dense_layer = Dense(64, activation='relu')(dropout_layer)\n",
    "\n",
    "# Domain Output Layer\n",
    "domain_output = Dense(len(domain_encoder.classes_), activation='softmax', name='domain')(dense_layer)\n",
    "\n",
    "# Sub-Domain Output Layer\n",
    "sub_domain_output = Dense(len(sub_domain_encoder.classes_), activation='softmax', name='sub_domain')(dense_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[domain_output, sub_domain_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ domain (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sub_domain (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,730</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚  \u001b[38;5;34m1,280,000\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m49,408\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m4,160\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ domain (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚        \u001b[38;5;34m195\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sub_domain (\u001b[38;5;33mDense\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        â”‚      \u001b[38;5;34m2,730\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,493</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,336,493\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,493</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,336,493\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with separate metrics for each output\n",
    "model.compile(optimizer='adam',\n",
    "              loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "              metrics=[['accuracy'], ['accuracy']])  \n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 39ms/step - domain_accuracy: 0.8460 - domain_loss: 0.3823 - loss: 2.5950 - sub_domain_accuracy: 0.2308 - sub_domain_loss: 2.2127 - val_domain_accuracy: 0.9672 - val_domain_loss: 0.0930 - val_loss: 1.6820 - val_sub_domain_accuracy: 0.4113 - val_sub_domain_loss: 1.5889\n",
      "Epoch 2/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - domain_accuracy: 0.9759 - domain_loss: 0.0718 - loss: 1.6182 - sub_domain_accuracy: 0.4145 - sub_domain_loss: 1.5465 - val_domain_accuracy: 0.9875 - val_domain_loss: 0.0420 - val_loss: 1.1295 - val_sub_domain_accuracy: 0.6025 - val_sub_domain_loss: 1.0875\n",
      "Epoch 3/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 46ms/step - domain_accuracy: 0.9911 - domain_loss: 0.0308 - loss: 1.0833 - sub_domain_accuracy: 0.6161 - sub_domain_loss: 1.0525 - val_domain_accuracy: 0.9878 - val_domain_loss: 0.0419 - val_loss: 0.9342 - val_sub_domain_accuracy: 0.7082 - val_sub_domain_loss: 0.8923\n",
      "Epoch 4/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 39ms/step - domain_accuracy: 0.9935 - domain_loss: 0.0211 - loss: 0.8296 - sub_domain_accuracy: 0.7300 - sub_domain_loss: 0.8084 - val_domain_accuracy: 0.9877 - val_domain_loss: 0.0410 - val_loss: 0.8257 - val_sub_domain_accuracy: 0.7556 - val_sub_domain_loss: 0.7847\n",
      "Epoch 5/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 39ms/step - domain_accuracy: 0.9958 - domain_loss: 0.0144 - loss: 0.6553 - sub_domain_accuracy: 0.8018 - sub_domain_loss: 0.6409 - val_domain_accuracy: 0.9887 - val_domain_loss: 0.0476 - val_loss: 0.8123 - val_sub_domain_accuracy: 0.7702 - val_sub_domain_loss: 0.7647\n",
      "Epoch 6/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 38ms/step - domain_accuracy: 0.9970 - domain_loss: 0.0113 - loss: 0.5570 - sub_domain_accuracy: 0.8352 - sub_domain_loss: 0.5458 - val_domain_accuracy: 0.9878 - val_domain_loss: 0.0590 - val_loss: 0.8136 - val_sub_domain_accuracy: 0.7825 - val_sub_domain_loss: 0.7546\n",
      "Epoch 7/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 39ms/step - domain_accuracy: 0.9969 - domain_loss: 0.0101 - loss: 0.4726 - sub_domain_accuracy: 0.8641 - sub_domain_loss: 0.4625 - val_domain_accuracy: 0.9891 - val_domain_loss: 0.0511 - val_loss: 0.8428 - val_sub_domain_accuracy: 0.7832 - val_sub_domain_loss: 0.7916\n",
      "Epoch 8/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 40ms/step - domain_accuracy: 0.9968 - domain_loss: 0.0102 - loss: 0.4171 - sub_domain_accuracy: 0.8795 - sub_domain_loss: 0.4069 - val_domain_accuracy: 0.9894 - val_domain_loss: 0.0572 - val_loss: 0.8577 - val_sub_domain_accuracy: 0.7883 - val_sub_domain_loss: 0.8005\n",
      "Epoch 9/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - domain_accuracy: 0.9970 - domain_loss: 0.0094 - loss: 0.3716 - sub_domain_accuracy: 0.8938 - sub_domain_loss: 0.3622 - val_domain_accuracy: 0.9884 - val_domain_loss: 0.0628 - val_loss: 0.8971 - val_sub_domain_accuracy: 0.7868 - val_sub_domain_loss: 0.8342\n",
      "Epoch 10/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 39ms/step - domain_accuracy: 0.9979 - domain_loss: 0.0078 - loss: 0.3209 - sub_domain_accuracy: 0.9088 - sub_domain_loss: 0.3131 - val_domain_accuracy: 0.9897 - val_domain_loss: 0.0597 - val_loss: 0.8814 - val_sub_domain_accuracy: 0.7838 - val_sub_domain_loss: 0.8217\n",
      "Epoch 11/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - domain_accuracy: 0.9972 - domain_loss: 0.0083 - loss: 0.2923 - sub_domain_accuracy: 0.9190 - sub_domain_loss: 0.2840 - val_domain_accuracy: 0.9897 - val_domain_loss: 0.0636 - val_loss: 0.9910 - val_sub_domain_accuracy: 0.7840 - val_sub_domain_loss: 0.9273\n",
      "Epoch 12/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 40ms/step - domain_accuracy: 0.9980 - domain_loss: 0.0061 - loss: 0.2463 - sub_domain_accuracy: 0.9295 - sub_domain_loss: 0.2402 - val_domain_accuracy: 0.9883 - val_domain_loss: 0.0629 - val_loss: 1.0171 - val_sub_domain_accuracy: 0.7844 - val_sub_domain_loss: 0.9542\n",
      "Epoch 13/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 45ms/step - domain_accuracy: 0.9981 - domain_loss: 0.0066 - loss: 0.2279 - sub_domain_accuracy: 0.9360 - sub_domain_loss: 0.2213 - val_domain_accuracy: 0.9889 - val_domain_loss: 0.0768 - val_loss: 1.0704 - val_sub_domain_accuracy: 0.7860 - val_sub_domain_loss: 0.9936\n",
      "Epoch 14/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 41ms/step - domain_accuracy: 0.9981 - domain_loss: 0.0067 - loss: 0.2106 - sub_domain_accuracy: 0.9409 - sub_domain_loss: 0.2039 - val_domain_accuracy: 0.9886 - val_domain_loss: 0.0683 - val_loss: 1.0897 - val_sub_domain_accuracy: 0.7818 - val_sub_domain_loss: 1.0214\n",
      "Epoch 15/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 41ms/step - domain_accuracy: 0.9980 - domain_loss: 0.0060 - loss: 0.1948 - sub_domain_accuracy: 0.9456 - sub_domain_loss: 0.1888 - val_domain_accuracy: 0.9876 - val_domain_loss: 0.0766 - val_loss: 1.1441 - val_sub_domain_accuracy: 0.7813 - val_sub_domain_loss: 1.0674\n",
      "Epoch 16/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 43ms/step - domain_accuracy: 0.9979 - domain_loss: 0.0065 - loss: 0.1798 - sub_domain_accuracy: 0.9509 - sub_domain_loss: 0.1733 - val_domain_accuracy: 0.9891 - val_domain_loss: 0.0771 - val_loss: 1.1746 - val_sub_domain_accuracy: 0.7853 - val_sub_domain_loss: 1.0975\n",
      "Epoch 17/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 41ms/step - domain_accuracy: 0.9978 - domain_loss: 0.0072 - loss: 0.1709 - sub_domain_accuracy: 0.9541 - sub_domain_loss: 0.1637 - val_domain_accuracy: 0.9888 - val_domain_loss: 0.0752 - val_loss: 1.2407 - val_sub_domain_accuracy: 0.7827 - val_sub_domain_loss: 1.1655\n",
      "Epoch 18/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 45ms/step - domain_accuracy: 0.9981 - domain_loss: 0.0067 - loss: 0.1570 - sub_domain_accuracy: 0.9578 - sub_domain_loss: 0.1503 - val_domain_accuracy: 0.9880 - val_domain_loss: 0.0794 - val_loss: 1.2204 - val_sub_domain_accuracy: 0.7837 - val_sub_domain_loss: 1.1409\n",
      "Epoch 19/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 53ms/step - domain_accuracy: 0.9980 - domain_loss: 0.0067 - loss: 0.1471 - sub_domain_accuracy: 0.9603 - sub_domain_loss: 0.1403 - val_domain_accuracy: 0.9890 - val_domain_loss: 0.0748 - val_loss: 1.2331 - val_sub_domain_accuracy: 0.7834 - val_sub_domain_loss: 1.1583\n",
      "Epoch 20/20\n",
      "\u001b[1m5260/5260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 54ms/step - domain_accuracy: 0.9982 - domain_loss: 0.0057 - loss: 0.1398 - sub_domain_accuracy: 0.9617 - sub_domain_loss: 0.1340 - val_domain_accuracy: 0.9869 - val_domain_loss: 0.1015 - val_loss: 1.4372 - val_sub_domain_accuracy: 0.7796 - val_sub_domain_loss: 1.3357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, [y_domain_train, y_sub_train],\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, [y_domain_val, y_sub_val]),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m658/658\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - domain_accuracy: 0.9865 - domain_loss: 0.1062 - loss: 1.4629 - sub_domain_accuracy: 0.7759 - sub_domain_loss: 1.3567\n",
      "Validation Accuracy - Domain: 0.9869, Sub-Domain: 0.7796\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation set\n",
    "val_loss, val_domain_loss, val_sub_loss, val_domain_acc, val_sub_acc = model.evaluate(\n",
    "    X_val, [y_domain_val, y_sub_val])\n",
    "print(\n",
    "    f\"Validation Accuracy - Domain: {val_domain_acc:.4f}, Sub-Domain: {val_sub_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted Domain: ['Ecommerce']\n",
      "Predicted Sub-Domain: ['Household']\n"
     ]
    }
   ],
   "source": [
    "description_input = [\"\"\"Battery Details- Type: Tall tubular batteryCapacity : 200Ah/12V: Construction: rugged construction\n",
    "Warranty -66 months ( 48 FOC+18Pro Rata)\n",
    "Dimension (in cm) - 512x192x466\n",
    "Weight- 64.8K.G\"\"\"]\n",
    "description_seq = tokenizer.texts_to_sequences(description_input)\n",
    "description_padded = pad_sequences(description_seq, padding='post', maxlen=100)\n",
    "\n",
    "domain_pred, sub_domain_pred = model.predict(description_padded)\n",
    "domain_pred_label = domain_encoder.inverse_transform(\n",
    "    domain_pred.argmax(axis=1))\n",
    "sub_domain_pred_label = sub_domain_encoder.inverse_transform(\n",
    "    sub_domain_pred.argmax(axis=1))\n",
    "\n",
    "print(f\"Predicted Domain: {domain_pred_label}\")\n",
    "print(f\"Predicted Sub-Domain: {sub_domain_pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and necessary objects saved successfully! ğŸ¯\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model.save(\"../models/neural_network/multi_label_model.keras\")\n",
    "\n",
    "# Save the tokenizer\n",
    "with open(\"../models/neural_network/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Save Label Encoders\n",
    "with open(\"../models/neural_network/domain_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(domain_encoder, f)\n",
    "\n",
    "with open(\"../models/neural_network/sub_domain_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sub_domain_encoder, f)\n",
    "\n",
    "print(\"Model and necessary objects saved successfully! ğŸ¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = load_model(\"../models/neural_network/multi_label_model.h5\")\n",
    "\n",
    "# Load Tokenizer\n",
    "with open(\"../models/neural_network/tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load Label Encoders\n",
    "with open(\"../models/neural_network/domain_encoder.pkl\", \"rb\") as f:\n",
    "    domain_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../models/neural_network/sub_domain_encoder.pkl\", \"rb\") as f:\n",
    "    sub_domain_encoder = pickle.load(f)\n",
    "\n",
    "print(\"Model and necessary objects loaded successfully! ğŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras Tuner\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from keras_tuner import HyperModel, Hyperband\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define HyperModel for Tuning\n",
    "class TextClassifierHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "        # Tune Embedding Layer size\n",
    "        embedding_dim = hp.Int(\n",
    "            'embedding_dim', min_value=64, max_value=256, step=64)\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=10000, output_dim=embedding_dim, input_length=X.shape[1])(input_layer)\n",
    "\n",
    "        # Tune LSTM Units\n",
    "        lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "        lstm_layer = LSTM(lstm_units, return_sequences=False)(embedding_layer)\n",
    "\n",
    "        # Tune Dropout Rate\n",
    "        dropout_rate = hp.Float(\n",
    "            'dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "        dropout_layer = Dropout(dropout_rate)(lstm_layer)\n",
    "\n",
    "        # Tune Dense Layer Units\n",
    "        dense_units = hp.Int('dense_units', min_value=32,\n",
    "                             max_value=128, step=32)\n",
    "        dense_layer = Dense(dense_units, activation='relu')(dropout_layer)\n",
    "\n",
    "        # Domain Output Layer\n",
    "        domain_output = Dense(len(domain_encoder.classes_),\n",
    "                              activation='softmax', name='domain')(dense_layer)\n",
    "\n",
    "        # Sub-Domain Output Layer\n",
    "        sub_domain_output = Dense(len(\n",
    "            sub_domain_encoder.classes_), activation='softmax', name='sub_domain')(dense_layer)\n",
    "\n",
    "        # Define Model\n",
    "        model = Model(inputs=input_layer, outputs=[\n",
    "                      domain_output, sub_domain_output])\n",
    "\n",
    "        # Tune Learning Rate\n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss=['categorical_crossentropy',\n",
    "                            'categorical_crossentropy'],\n",
    "                      metrics=['accuracy', 'accuracy'])\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jay\\CDAC\\Project\\Domain Classifier\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Tuner\n",
    "tuner = Hyperband(TextClassifierHyperModel(),\n",
    "                  objective=keras_tuner.Objective(\n",
    "                      \"val_sub_domain_accuracy\", direction=\"max\"),\n",
    "                  max_epochs=10,\n",
    "                  factor=3,\n",
    "                  directory='hyperband_tuning',\n",
    "                  project_name='text_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for best hyperparameters\n",
    "tuner.search(X_train, [y_domain_train, y_sub_train],\n",
    "             epochs=10,\n",
    "             batch_size=16,\n",
    "             validation_data=(X_val, [y_domain_val, y_sub_val]),\n",
    "             verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get Best Hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters Found:\n",
    "Embedding Size: {best_hps.get('embedding_dim')}\n",
    "LSTM Units: {best_hps.get('lstm_units')}\n",
    "Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "Dense Units: {best_hps.get('dense_units')}\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Best Model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = best_model.fit(\n",
    "    X_train, [y_domain_train, y_sub_train],\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, [y_domain_val, y_sub_val]),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "best_model.save(\"../models/neural_network/best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate Model on Validation Data\n",
    "val_loss, val_domain_loss, val_sub_loss, val_domain_acc, val_sub_acc = best_model.evaluate(\n",
    "    X_val, [y_domain_val, y_sub_val])\n",
    "print(\n",
    "    f\"Validation Accuracy - Domain: {val_domain_acc:.4f}, Sub-Domain: {val_sub_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
